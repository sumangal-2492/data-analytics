display(Javascript("""
    require.undef('click-handler');
    define('click-handler', ['plotly'], function(Plotly) {
        function clickHandler(msg) {
            var selectedYear = msg.points[0].data.name.split(' ')[1].slice(1, -1);
            var selectedMonthIndex = msg.points[0].x % 12 || 12;
            var selectedMonth = Array.from(calendar.month_abbr.values())[selectedMonthIndex];
            var selectedCategory = msg.points[0].data.name.split(' ')[2];
            
            var selectedData = msg.points[0].data.name.split(' ')[3].split('(')[1].split(')')[0];
            var selectedUnit = selectedData.split(':')[0];
            var selectedSpend = selectedData.split(':')[1];
            
            var buFig = {
                'data': [{'x': [" + selectedUnit + "], 'y': [" + selectedSpend + "], 'type': 'bar'}],
                'layout': {
                    'title': 'Business Unit vs Spend Trend for ' + selectedCategory + ' in ' + selectedMonth + ' ' + selectedYear,
                    'xaxis': {'title': 'Business Unit'},
                    'yaxis': {'title': 'Spend'}
                }
            };
            Plotly.newPlot('bu_plot', buFig.data, buFig.layout);
        }
        return {
            clickHandler: clickHandler
        };
    });

    require(['click-handler', 'plotly'], function(CH, Plotly) {
        Plotly.newPlot('graph', [], {});
        var plot = document.getElementById('graph');
        plot.on('plotly_click', CH.clickHandler);
    });
    """))
************************************


import shap
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Assuming `data` is your DataFrame and it already has an 'anomaly' column from Isolation Forest
# Prepare the dataset for training a surrogate model
X = data[['Month', 'Spend']]  # Simplified feature set; you might want to include more features
y = data['anomaly']  # Labels generated by Isolation Forest

# Encode categorical features as necessary
# For this example, all features are numerical already

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Decision Tree Classifier as a surrogate model
clf = DecisionTreeClassifier(max_depth=5, random_state=42)
clf.fit(X_train, y_train)

# Evaluate the surrogate model
y_pred = clf.predict(X_test)
print(f"Accuracy of surrogate model: {accuracy_score(y_test, y_pred):.2f}")

# Apply SHAP to understand the model
explainer = shap.Explainer(clf, X_train)
shap_values = explainer.shap_values(X_test)

# Visualize the SHAP values for the first prediction
shap.initjs()
shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_test.iloc[0,:])
